{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder,OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import optuna\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>TSH</th>\n",
       "      <th>T3</th>\n",
       "      <th>TT4</th>\n",
       "      <th>T4U</th>\n",
       "      <th>FTI</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>Female</td>\n",
       "      <td>68.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.02</td>\n",
       "      <td>47.0</td>\n",
       "      <td>hypothyroid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.06</td>\n",
       "      <td>85.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.20</td>\n",
       "      <td>2.3</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1.08</td>\n",
       "      <td>96.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>Female</td>\n",
       "      <td>5.90</td>\n",
       "      <td>2.1</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>105.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.4</td>\n",
       "      <td>107.0</td>\n",
       "      <td>1.13</td>\n",
       "      <td>95.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex    TSH   T3    TT4   T4U    FTI       target\n",
       "0   63  Female  68.00  0.0   48.0  1.02   47.0  hypothyroid\n",
       "1   36  Female   1.50  2.4   90.0  1.06   85.0     negative\n",
       "2   40  Female   1.20  2.3  104.0  1.08   96.0     negative\n",
       "3   40  Female   5.90  2.1   88.0  0.84  105.0     negative\n",
       "4   77  Female   0.05  2.4  107.0  1.13   95.0     negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'sex', 'TSH', 'T3', 'TT4', 'T4U', 'FTI', 'target']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_be_scaled = ['age','TSH','T3','TT4','T4U','FTI']\n",
    "features_to_be_encoded = ['sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline(steps=[(\"scaler\",StandardScaler())])\n",
    "cat_pipeline = Pipeline(steps=[(\"one_hot_encoder\",OneHotEncoder()),(\"scaler\",StandardScaler(with_mean=False))])\n",
    "preprocessor = ColumnTransformer([\n",
    "                (\"num_pipeline\",num_pipeline,features_to_be_scaled),\n",
    "                (\"cat_pipeline\",cat_pipeline,features_to_be_encoded)\n",
    "                ])\n",
    "# cat_pipeline = Pipeline(steps=[(\"label_encoder\", LabelEncoder()), (\"scaler\", StandardScaler(with_mean=False))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "le= LabelEncoder()\n",
    "df['target'] = le.fit_transform(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['target'],axis=1)\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify= y)\n",
    "# train_set, test_set=train_test_split(df,test_size=0.2,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le = LabelEncoder()\n",
    "# df[final_cat_cols] = df[features_to_be_encoded].apply(le.fit_transform)\n",
    "# scaler = StandardScaler()\n",
    "# df[final_num_cols] = scaler.fit_transform(df[final_num_cols])\n",
    "# df = pd.concat([df['age'], df[final_cat_cols], df[final_num_cols]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'validation_0': OrderedDict([('merror',\n",
       "               [0.01651794190241124,\n",
       "                0.01765711030947409,\n",
       "                0.01613821910005696,\n",
       "                0.01613821910005696,\n",
       "                0.01651794190241124,\n",
       "                0.01670780330358838,\n",
       "                0.01651794190241124,\n",
       "                0.01575849629770268,\n",
       "                0.0153787734953484,\n",
       "                0.0153787734953484,\n",
       "                0.01461932789063983,\n",
       "                0.01442946648946269,\n",
       "                0.01385988228593127,\n",
       "                0.01385988228593127,\n",
       "                0.01385988228593127,\n",
       "                0.01385988228593127,\n",
       "                0.01385988228593127,\n",
       "                0.01367002088475413,\n",
       "                0.01348015948357699,\n",
       "                0.01348015948357699,\n",
       "                0.01348015948357699,\n",
       "                0.01348015948357699,\n",
       "                0.01310043668122271,\n",
       "                0.01310043668122271,\n",
       "                0.01348015948357699,\n",
       "                0.01329029808239985,\n",
       "                0.01291057528004557,\n",
       "                0.01196126827415986,\n",
       "                0.01177140687298272,\n",
       "                0.01177140687298272,\n",
       "                0.01139168407062844,\n",
       "                0.01082209986709702,\n",
       "                0.01044237706474274,\n",
       "                0.0102525156635656,\n",
       "                0.01006265426238846,\n",
       "                0.00949307005885703,\n",
       "                0.00968293146003417,\n",
       "                0.00930320865767989,\n",
       "                0.00911334725650275,\n",
       "                0.00892348585532561,\n",
       "                0.00873362445414847,\n",
       "                0.00873362445414847,\n",
       "                0.00892348585532561,\n",
       "                0.00892348585532561,\n",
       "                0.00892348585532561,\n",
       "                0.00873362445414847,\n",
       "                0.00854376305297133,\n",
       "                0.00816404025061705,\n",
       "                0.00816404025061705,\n",
       "                0.00778431744826277,\n",
       "                0.00778431744826277,\n",
       "                0.00759445604708563,\n",
       "                0.00759445604708563,\n",
       "                0.00759445604708563,\n",
       "                0.00759445604708563,\n",
       "                0.00759445604708563,\n",
       "                0.00778431744826277,\n",
       "                0.00759445604708563,\n",
       "                0.00778431744826277,\n",
       "                0.00778431744826277,\n",
       "                0.00740459464590849,\n",
       "                0.00740459464590849,\n",
       "                0.00740459464590849,\n",
       "                0.00740459464590849,\n",
       "                0.00721473324473135,\n",
       "                0.00702487184355421,\n",
       "                0.00721473324473135,\n",
       "                0.00702487184355421,\n",
       "                0.00702487184355421,\n",
       "                0.00683501044237706,\n",
       "                0.00683501044237706,\n",
       "                0.00683501044237706,\n",
       "                0.00683501044237706,\n",
       "                0.00645528764002278,\n",
       "                0.00645528764002278,\n",
       "                0.00645528764002278,\n",
       "                0.00626542623884564,\n",
       "                0.0060755648376685,\n",
       "                0.0060755648376685,\n",
       "                0.0060755648376685,\n",
       "                0.00588570343649136,\n",
       "                0.00569584203531422,\n",
       "                0.00569584203531422,\n",
       "                0.00531611923295994,\n",
       "                0.00531611923295994,\n",
       "                0.00531611923295994,\n",
       "                0.00531611923295994,\n",
       "                0.00531611923295994,\n",
       "                0.00531611923295994,\n",
       "                0.0051262578317828,\n",
       "                0.0051262578317828,\n",
       "                0.00493639643060566,\n",
       "                0.00493639643060566,\n",
       "                0.00493639643060566,\n",
       "                0.00493639643060566,\n",
       "                0.00493639643060566,\n",
       "                0.00493639643060566,\n",
       "                0.00474653502942852,\n",
       "                0.00493639643060566,\n",
       "                0.00474653502942852]),\n",
       "              ('mlogloss',\n",
       "               [0.9590718809445217,\n",
       "                0.8435521213949938,\n",
       "                0.746316193063141,\n",
       "                0.6635315383161882,\n",
       "                0.5920961478165256,\n",
       "                0.530156421982769,\n",
       "                0.4759517619635635,\n",
       "                0.42838017750288837,\n",
       "                0.38634686289418463,\n",
       "                0.3494006088376611,\n",
       "                0.316740367287858,\n",
       "                0.2878374133024945,\n",
       "                0.2621959514911699,\n",
       "                0.2393999432609863,\n",
       "                0.21911623030023916,\n",
       "                0.2008135181315737,\n",
       "                0.18435675477266356,\n",
       "                0.16952300077091703,\n",
       "                0.15624683894654118,\n",
       "                0.14425664124060836,\n",
       "                0.13346806436477224,\n",
       "                0.12371532125453331,\n",
       "                0.11476252728782117,\n",
       "                0.1067046062719874,\n",
       "                0.09942892758635115,\n",
       "                0.09293113348718067,\n",
       "                0.0870839186551699,\n",
       "                0.08171665306992225,\n",
       "                0.07680804493552551,\n",
       "                0.07238920287884955,\n",
       "                0.0684294209481191,\n",
       "                0.06489661805089814,\n",
       "                0.0615862364719302,\n",
       "                0.05858863084639796,\n",
       "                0.05584635392668828,\n",
       "                0.05334751224504242,\n",
       "                0.05099244896999364,\n",
       "                0.04888844177464968,\n",
       "                0.04699468951391522,\n",
       "                0.04516077604203517,\n",
       "                0.04348829869698653,\n",
       "                0.0418631366496679,\n",
       "                0.04038549821437656,\n",
       "                0.03898855128689953,\n",
       "                0.03771118455884215,\n",
       "                0.03662414134778712,\n",
       "                0.0355785963901246,\n",
       "                0.03466676338677453,\n",
       "                0.03377351246324007,\n",
       "                0.03289184976158371,\n",
       "                0.03206337405243496,\n",
       "                0.03119693036209378,\n",
       "                0.03043130232675101,\n",
       "                0.02969761104639482,\n",
       "                0.02907206338104614,\n",
       "                0.02843778720784219,\n",
       "                0.02787891154038505,\n",
       "                0.02735980577953973,\n",
       "                0.02687953273683167,\n",
       "                0.02634312524730794,\n",
       "                0.0258475636053243,\n",
       "                0.02540675709397167,\n",
       "                0.02490283100782145,\n",
       "                0.02448795191561798,\n",
       "                0.02409409685082485,\n",
       "                0.02363527824127301,\n",
       "                0.02323622406002906,\n",
       "                0.02285347691154398,\n",
       "                0.0224927234317869,\n",
       "                0.0221951014984314,\n",
       "                0.02175643414209049,\n",
       "                0.02140066360601936,\n",
       "                0.02110245078171075,\n",
       "                0.02077104771511402,\n",
       "                0.02048927197686259,\n",
       "                0.0201667406039386,\n",
       "                0.01990279132388539,\n",
       "                0.01952807307623957,\n",
       "                0.01911214208368408,\n",
       "                0.01868416314270225,\n",
       "                0.01826119621864106,\n",
       "                0.01782411279595146,\n",
       "                0.01748842982661078,\n",
       "                0.01721367933813487,\n",
       "                0.01691164792738377,\n",
       "                0.01662531679577883,\n",
       "                0.01640146380121833,\n",
       "                0.01618969306800297,\n",
       "                0.015914306942432,\n",
       "                0.01570544384999298,\n",
       "                0.01548220777837776,\n",
       "                0.0151174421729821,\n",
       "                0.01490445800310721,\n",
       "                0.0146497020839616,\n",
       "                0.01446468828747001,\n",
       "                0.01423975163807371,\n",
       "                0.01405603717752864,\n",
       "                0.01387468786500977,\n",
       "                0.01371002189061074,\n",
       "                0.01350358136944513])]),\n",
       " 'validation_1': OrderedDict([('merror',\n",
       "               [0.01822323462414579,\n",
       "                0.01898253606681853,\n",
       "                0.01822323462414579,\n",
       "                0.01822323462414579,\n",
       "                0.01594533029612756,\n",
       "                0.01594533029612756,\n",
       "                0.0167046317388003,\n",
       "                0.01594533029612756,\n",
       "                0.01594533029612756,\n",
       "                0.01594533029612756,\n",
       "                0.01594533029612756,\n",
       "                0.01594533029612756,\n",
       "                0.01594533029612756,\n",
       "                0.01594533029612756,\n",
       "                0.01594533029612756,\n",
       "                0.01594533029612756,\n",
       "                0.01594533029612756,\n",
       "                0.01594533029612756,\n",
       "                0.01594533029612756,\n",
       "                0.01594533029612756,\n",
       "                0.01594533029612756,\n",
       "                0.01594533029612756,\n",
       "                0.01594533029612756,\n",
       "                0.01594533029612756,\n",
       "                0.01594533029612756,\n",
       "                0.01594533029612756,\n",
       "                0.01594533029612756,\n",
       "                0.01366742596810934,\n",
       "                0.01366742596810934,\n",
       "                0.01366742596810934,\n",
       "                0.01366742596810934,\n",
       "                0.0129081245254366,\n",
       "                0.0129081245254366,\n",
       "                0.0129081245254366,\n",
       "                0.0129081245254366,\n",
       "                0.0129081245254366,\n",
       "                0.0129081245254366,\n",
       "                0.0129081245254366,\n",
       "                0.01214882308276386,\n",
       "                0.0129081245254366,\n",
       "                0.0129081245254366,\n",
       "                0.0129081245254366,\n",
       "                0.01366742596810934,\n",
       "                0.01366742596810934,\n",
       "                0.0129081245254366,\n",
       "                0.0129081245254366,\n",
       "                0.0129081245254366,\n",
       "                0.0129081245254366,\n",
       "                0.0129081245254366,\n",
       "                0.0129081245254366,\n",
       "                0.0129081245254366,\n",
       "                0.0129081245254366,\n",
       "                0.0129081245254366,\n",
       "                0.0129081245254366,\n",
       "                0.0129081245254366,\n",
       "                0.0129081245254366,\n",
       "                0.01214882308276386,\n",
       "                0.01214882308276386,\n",
       "                0.01214882308276386,\n",
       "                0.01214882308276386,\n",
       "                0.01138952164009112,\n",
       "                0.01138952164009112,\n",
       "                0.01214882308276386,\n",
       "                0.01138952164009112,\n",
       "                0.01214882308276386,\n",
       "                0.01214882308276386,\n",
       "                0.01138952164009112,\n",
       "                0.01138952164009112,\n",
       "                0.01138952164009112,\n",
       "                0.01138952164009112,\n",
       "                0.00987091875474563,\n",
       "                0.00987091875474563,\n",
       "                0.00987091875474563,\n",
       "                0.00987091875474563,\n",
       "                0.00987091875474563,\n",
       "                0.00987091875474563,\n",
       "                0.00987091875474563,\n",
       "                0.00987091875474563,\n",
       "                0.00987091875474563,\n",
       "                0.00987091875474563,\n",
       "                0.00987091875474563,\n",
       "                0.00987091875474563,\n",
       "                0.00987091875474563,\n",
       "                0.00987091875474563,\n",
       "                0.00987091875474563,\n",
       "                0.00911161731207289,\n",
       "                0.00911161731207289,\n",
       "                0.00911161731207289,\n",
       "                0.00987091875474563,\n",
       "                0.00911161731207289,\n",
       "                0.00911161731207289,\n",
       "                0.00911161731207289,\n",
       "                0.00911161731207289,\n",
       "                0.00911161731207289,\n",
       "                0.00911161731207289,\n",
       "                0.00911161731207289,\n",
       "                0.00911161731207289,\n",
       "                0.00911161731207289,\n",
       "                0.00911161731207289,\n",
       "                0.00911161731207289]),\n",
       "              ('mlogloss',\n",
       "               [0.9595945747222697,\n",
       "                0.844296270414293,\n",
       "                0.7474002309975157,\n",
       "                0.6647181906026697,\n",
       "                0.5935659541174961,\n",
       "                0.5317934647870046,\n",
       "                0.4779041204926817,\n",
       "                0.4304801413029907,\n",
       "                0.3885853904028598,\n",
       "                0.35188429445684544,\n",
       "                0.3194236597873627,\n",
       "                0.2907333045903715,\n",
       "                0.26531723779806515,\n",
       "                0.24260827481475125,\n",
       "                0.22250563514983918,\n",
       "                0.20439795371294928,\n",
       "                0.1881294448944141,\n",
       "                0.17345716590988156,\n",
       "                0.1604445533276781,\n",
       "                0.14866198497508273,\n",
       "                0.13800313389360136,\n",
       "                0.12861328538091416,\n",
       "                0.1199578542542349,\n",
       "                0.11228642473527674,\n",
       "                0.10527678641321628,\n",
       "                0.09893579893351596,\n",
       "                0.09337262086847467,\n",
       "                0.08834482710483224,\n",
       "                0.08383174441986764,\n",
       "                0.07960128124263038,\n",
       "                0.07594030494423372,\n",
       "                0.0727415798216402,\n",
       "                0.06971102416933986,\n",
       "                0.06692138310428497,\n",
       "                0.06421915014488686,\n",
       "                0.06202839494837716,\n",
       "                0.05985867680420275,\n",
       "                0.05805367061793352,\n",
       "                0.05642795852253223,\n",
       "                0.05500656108307563,\n",
       "                0.05372336417883521,\n",
       "                0.05254208301841059,\n",
       "                0.05145863362360992,\n",
       "                0.0501775924468536,\n",
       "                0.04909307872572449,\n",
       "                0.04799335716283776,\n",
       "                0.04704941569063063,\n",
       "                0.04611537499486235,\n",
       "                0.04533893604824375,\n",
       "                0.04447214673298016,\n",
       "                0.04369223123308817,\n",
       "                0.04273825762800493,\n",
       "                0.04200671158162431,\n",
       "                0.0416895322856651,\n",
       "                0.04095364821209921,\n",
       "                0.04035700540232982,\n",
       "                0.03969579113819888,\n",
       "                0.03910446314098018,\n",
       "                0.03868039545936167,\n",
       "                0.03820434166719584,\n",
       "                0.03789178069283862,\n",
       "                0.0375731072272616,\n",
       "                0.03719829072420547,\n",
       "                0.03705803953212295,\n",
       "                0.03682584910732733,\n",
       "                0.03639368314924314,\n",
       "                0.03622859271084812,\n",
       "                0.03613442820818612,\n",
       "                0.03604089584576013,\n",
       "                0.03579166728054543,\n",
       "                0.03559568383442429,\n",
       "                0.03540574486977149,\n",
       "                0.03521129990503229,\n",
       "                0.0350888671953922,\n",
       "                0.03500892303595157,\n",
       "                0.03479232125861313,\n",
       "                0.0347255687390213,\n",
       "                0.0345446176883703,\n",
       "                0.03431336771547066,\n",
       "                0.03417095292706362,\n",
       "                0.03397743603081677,\n",
       "                0.03379423768632962,\n",
       "                0.03365886238501382,\n",
       "                0.03351483909806043,\n",
       "                0.03345972394528986,\n",
       "                0.03337694493469082,\n",
       "                0.03333125892247748,\n",
       "                0.03332505067081605,\n",
       "                0.03326206169681727,\n",
       "                0.03312734619834271,\n",
       "                0.03307611884125145,\n",
       "                0.03304108317450883,\n",
       "                0.03293000291010677,\n",
       "                0.03293834946598011,\n",
       "                0.03286640851468001,\n",
       "                0.03278732513822809,\n",
       "                0.03267400213570065,\n",
       "                0.03267717519357811,\n",
       "                0.0326100937201749,\n",
       "                0.03244847653535952])])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weights = compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=y_train)\n",
    "xgb=XGBClassifier(objective='multi:softmax', \n",
    "                            num_class=3, \n",
    "                            missing=1,\n",
    "                            gamma=0, # default gamma value\n",
    "                            learning_rate=0.1,\n",
    "                            max_depth=5, # re-optimized from v2\n",
    "                            reg_lambda=1, # default L2 value\n",
    "                            #subsample=0.8, # tried but not ideal\n",
    "                            #colsample_bytree=0.3, # tried but not ideal\n",
    "                            early_stopping_rounds=10,\n",
    "                            eval_metric=['merror','mlogloss'],\n",
    "                            seed=42)\n",
    "\n",
    "xgb.fit(X_train, \n",
    "            y_train,\n",
    "            verbose=0, # set to 1 to see xgb training round intermediate results\n",
    "            sample_weight=sample_weights, # class weights to combat unbalanced 'target'\n",
    "            eval_set=[(X_train, y_train), (X_test, y_test)])\n",
    "\n",
    "results = xgb.evals_result()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9908883826879271"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = xgb.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def objective(trial):\n",
    "    # Define parameters to tune\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000, step=100),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 15),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "        # \"max_features\": trial.suggest_categorical(\"max_features\", [\"auto\", \"sqrt\", \"log2\"]),\n",
    "        \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "    }\n",
    "    \n",
    "    # Initialize the Random Forest Classifier with the parameters\n",
    "    rf_model = RandomForestClassifier(**params)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    accuracy = rf_model.score(X_train, y_train)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-08 01:00:50,478] A new study created in memory with name: no-name-6c253aff-4738-4290-b8d0-a13da6025a2d\n",
      "[I 2024-08-08 01:00:52,142] Trial 0 finished with value: 0.9863299791152459 and parameters: {'n_estimators': 100, 'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 0 with value: 0.9863299791152459.\n",
      "[I 2024-08-08 01:00:59,112] Trial 1 finished with value: 0.9827226124928802 and parameters: {'n_estimators': 900, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 7, 'bootstrap': False}. Best is trial 0 with value: 0.9863299791152459.\n",
      "[I 2024-08-08 01:01:04,428] Trial 2 finished with value: 0.985190810708183 and parameters: {'n_estimators': 900, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 0 with value: 0.9863299791152459.\n",
      "[I 2024-08-08 01:01:05,438] Trial 3 finished with value: 0.9794949686728688 and parameters: {'n_estimators': 200, 'max_depth': 3, 'min_samples_split': 17, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 0 with value: 0.9863299791152459.\n",
      "[I 2024-08-08 01:01:13,599] Trial 4 finished with value: 1.0 and parameters: {'n_estimators': 800, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:01:14,275] Trial 5 finished with value: 0.9794949686728688 and parameters: {'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 7, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:01:21,017] Trial 6 finished with value: 0.9876590089234859 and parameters: {'n_estimators': 800, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:01:22,500] Trial 7 finished with value: 0.9819631668881716 and parameters: {'n_estimators': 300, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:01:24,360] Trial 8 finished with value: 0.9914562369470287 and parameters: {'n_estimators': 200, 'max_depth': 8, 'min_samples_split': 14, 'min_samples_leaf': 5, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:01:25,187] Trial 9 finished with value: 0.9897474843364344 and parameters: {'n_estimators': 100, 'max_depth': 11, 'min_samples_split': 15, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:01:29,909] Trial 10 finished with value: 0.9844313651034745 and parameters: {'n_estimators': 600, 'max_depth': 15, 'min_samples_split': 20, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:01:34,448] Trial 11 finished with value: 0.9935447123599772 and parameters: {'n_estimators': 500, 'max_depth': 9, 'min_samples_split': 12, 'min_samples_leaf': 5, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:01:40,514] Trial 12 finished with value: 0.9984811087905828 and parameters: {'n_estimators': 600, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:01:46,894] Trial 13 finished with value: 0.9963926333776343 and parameters: {'n_estimators': 700, 'max_depth': 14, 'min_samples_split': 7, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:01:51,971] Trial 14 finished with value: 0.9988608315929371 and parameters: {'n_estimators': 500, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:01:55,378] Trial 15 finished with value: 0.9943041579646857 and parameters: {'n_estimators': 400, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:02:03,760] Trial 16 finished with value: 0.9952534649705714 and parameters: {'n_estimators': 1000, 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:02:10,642] Trial 17 finished with value: 0.9982912473894058 and parameters: {'n_estimators': 700, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:02:14,856] Trial 18 finished with value: 0.9939244351623315 and parameters: {'n_estimators': 500, 'max_depth': 15, 'min_samples_split': 9, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:02:21,686] Trial 19 finished with value: 0.9927852667552687 and parameters: {'n_estimators': 700, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 6, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:02:25,754] Trial 20 finished with value: 0.9969622175811658 and parameters: {'n_estimators': 400, 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:02:31,630] Trial 21 finished with value: 0.9982912473894058 and parameters: {'n_estimators': 600, 'max_depth': 13, 'min_samples_split': 11, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:02:40,054] Trial 22 finished with value: 0.9984811087905828 and parameters: {'n_estimators': 800, 'max_depth': 12, 'min_samples_split': 9, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:02:44,216] Trial 23 finished with value: 0.9994304157964686 and parameters: {'n_estimators': 400, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:02:48,115] Trial 24 finished with value: 0.9996202771976457 and parameters: {'n_estimators': 400, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:02:51,970] Trial 25 finished with value: 0.9981013859882286 and parameters: {'n_estimators': 400, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:02:54,369] Trial 26 finished with value: 0.99734194038352 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 4, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:02:57,263] Trial 27 finished with value: 0.9982912473894058 and parameters: {'n_estimators': 300, 'max_depth': 14, 'min_samples_split': 6, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:03:00,363] Trial 28 finished with value: 0.9840516423011202 and parameters: {'n_estimators': 400, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:03:08,844] Trial 29 finished with value: 0.9912663755458515 and parameters: {'n_estimators': 1000, 'max_depth': 14, 'min_samples_split': 8, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:03:11,074] Trial 30 finished with value: 0.9962027719764572 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:03:15,962] Trial 31 finished with value: 0.9990506929941143 and parameters: {'n_estimators': 500, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:03:20,544] Trial 32 finished with value: 0.9992405543952915 and parameters: {'n_estimators': 500, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:03:24,538] Trial 33 finished with value: 1.0 and parameters: {'n_estimators': 400, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:03:27,706] Trial 34 finished with value: 1.0 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:03:31,268] Trial 35 finished with value: 1.0 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:03:33,553] Trial 36 finished with value: 1.0 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:03:36,669] Trial 37 finished with value: 1.0 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:03:39,139] Trial 38 finished with value: 0.986519840516423 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 7, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:03:46,119] Trial 39 finished with value: 0.9899373457376115 and parameters: {'n_estimators': 900, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:03:47,075] Trial 40 finished with value: 0.9982912473894058 and parameters: {'n_estimators': 100, 'max_depth': 15, 'min_samples_split': 4, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:03:49,257] Trial 41 finished with value: 1.0 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:03:51,155] Trial 42 finished with value: 1.0 and parameters: {'n_estimators': 200, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:03:52,294] Trial 43 finished with value: 1.0 and parameters: {'n_estimators': 100, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:03:55,000] Trial 44 finished with value: 0.9998101385988228 and parameters: {'n_estimators': 300, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:03:56,985] Trial 45 finished with value: 1.0 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:03:58,734] Trial 46 finished with value: 0.9914562369470287 and parameters: {'n_estimators': 200, 'max_depth': 13, 'min_samples_split': 14, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:04:06,263] Trial 47 finished with value: 0.9946838807670401 and parameters: {'n_estimators': 800, 'max_depth': 11, 'min_samples_split': 19, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:04:08,096] Trial 48 finished with value: 0.9882285931270173 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 16, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2024-08-08 01:04:11,701] Trial 49 finished with value: 0.9906967913423201 and parameters: {'n_estimators': 300, 'max_depth': 14, 'min_samples_split': 6, 'min_samples_leaf': 8, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction = \"maximize\")\n",
    "study.optimize(objective, n_trials = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 50\n",
      "Best trial:\n",
      "  Value: 1.0\n",
      "  Params: \n",
      "    n_estimators: 800\n",
      "    max_depth: 14\n",
      "    min_samples_split: 2\n",
      "    min_samples_leaf: 1\n",
      "    bootstrap: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9931662870159453"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rf_model = RandomForestClassifier(n_estimators= 800,max_depth= 14,min_samples_split= 2,min_samples_leaf= 1,bootstrap= False)\n",
    "# rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = le.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'negative', 'negative', ..., 'hypothyroid', 'negative',\n",
       "       'negative'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting a sample instance \n",
    "new_instance = {\n",
    "    'age': 45,\n",
    "    'sex': 'Male',\n",
    "    'TSH': 2.5,\n",
    "    'T3': 1.0,\n",
    "    'TT4': 100.0,\n",
    "    'T4U': 1.1,\n",
    "    'FTI': 120.0\n",
    "}\n",
    "\n",
    "new_data = pd.DataFrame([new_instance])\n",
    "preprocessed_data = preprocessor.transform(new_data)\n",
    "predicted_target = rf_model.predict(preprocessed_data)\n",
    "decoded_target = le.inverse_transform(predicted_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_target[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
